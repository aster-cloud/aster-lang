# Lexer

Tokenizes canonicalized input. Produces tokens with position and INDENT/DEDENT.

```ts
import { lex } from 'aster-lang';
const tokens = lex(can);
```

