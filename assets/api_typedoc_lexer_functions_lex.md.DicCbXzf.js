import{_ as e,c as i,o as a,aj as n}from"./chunks/framework.Bz2R-749.js";const k=JSON.parse('{"title":"Function: lex()","description":"","frontmatter":{},"headers":[],"relativePath":"api/typedoc/lexer/functions/lex.md","filePath":"api/typedoc/lexer/functions/lex.md"}'),t={name:"api/typedoc/lexer/functions/lex.md"};function l(o,s,p,h,r,c){return a(),i("div",null,[...s[0]||(s[0]=[n(`<p><a href="./../../README.html"><strong>@wontlost-ltd/aster-lang</strong></a></p><hr><h1 id="function-lex" tabindex="-1">Function: lex() <a class="header-anchor" href="#function-lex" aria-label="Permalink to “Function: lex()”">​</a></h1><blockquote><p><strong>lex</strong>(<code>input</code>): <a href="./../../types/interfaces/Token.html"><code>Token</code></a>[]</p></blockquote><p>Defined in: <a href="https://github.com/wontlost-ltd/aster-lang/blob/08894f0ec715ec098e0d6fadc4b448f4f075653b/src/lexer.ts#L69" target="_blank" rel="noreferrer">lexer.ts:69</a></p><p>对规范化的 CNL 源代码进行词法分析，生成 Token 流。</p><p>这是 Aster 编译管道的第二步，将规范化的文本字符串转换为结构化的 token 序列， 为后续的语法分析阶段提供输入。</p><p><strong>Token 类型</strong>：</p><ul><li>关键字：<code>To</code>, <code>Return</code>, <code>Match</code>, <code>When</code>, <code>Define</code>, <code>It performs</code> 等</li><li>标识符：变量名、函数名、类型名</li><li>字面量：整数、浮点数、布尔值、字符串、null</li><li>运算符：<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>=</code>, <code>==</code>, <code>&lt;</code>, <code>&gt;</code> 等</li><li>标点符号：<code>.</code>, <code>,</code>, <code>:</code>, <code>(</code>, <code>)</code>, <code>{</code>, <code>}</code> 等</li><li>特殊 token：<code>INDENT</code>, <code>DEDENT</code>, <code>NEWLINE</code>, <code>EOF</code></li></ul><h2 id="parameters" tabindex="-1">Parameters <a class="header-anchor" href="#parameters" aria-label="Permalink to “Parameters”">​</a></h2><h3 id="input" tabindex="-1">input <a class="header-anchor" href="#input" aria-label="Permalink to “input”">​</a></h3><p><code>string</code></p><p>规范化后的 CNL 源代码（应先通过 canonicalizer.canonicalize 处理）</p><h2 id="returns" tabindex="-1">Returns <a class="header-anchor" href="#returns" aria-label="Permalink to “Returns”">​</a></h2><p><a href="./../../types/interfaces/Token.html"><code>Token</code></a>[]</p><p>Token 数组，每个 token 包含类型、值和位置信息</p><h2 id="throws" tabindex="-1">Throws <a class="header-anchor" href="#throws" aria-label="Permalink to “Throws”">​</a></h2><p>当遇到非法字符或缩进错误时抛出</p><h2 id="example" tabindex="-1">Example <a class="header-anchor" href="#example" aria-label="Permalink to “Example”">​</a></h2><div class="language-typescript"><button title="Copy Code" class="copy"></button><span class="lang">typescript</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { canonicalize, lex } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;@wontlost-ltd/aster-lang&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> src</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> \`This module is app.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">To greet, produce Text:</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  Return &quot;Hello&quot;.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">\`</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> canonical</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> canonicalize</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(src);</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> tokens</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> lex</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(canonical);</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// tokens 包含：MODULE_IS, IDENT(&quot;app&quot;), DOT, TO, IDENT(&quot;greet&quot;), ...</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">console.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">log</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(tokens.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">map</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">t</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =&gt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> t.kind));</span></span></code></pre></div>`,20)])])}const g=e(t,[["render",l]]);export{k as __pageData,g as default};
